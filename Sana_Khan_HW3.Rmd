---
output:
  html_document: default
  pdf_document: default
---
# Intro to Data Science - HW 3
##### Copyright Jeffrey Stanton, Jeffrey Saltz, and Jasmina Tacheva


```{r}
# Enter your name here: Sana Khan, IST 687, Homework 2, Due 1/1
```

### Attribution statement: (choose only one and delete the rest)


```{r}
# 1. I did this homework by myself, with help from the book and the professor.

```

### Reminders of things to practice from last week: 
Make a data frame		data.frame( ) <br>
Row index of max/min	which.max( )  which.min( )<br>
Sort value or order rows	sort( )   order( )<br>
Descriptive statistics 	mean( ) sum( ) max( ) <br>
Conditional statement	if (condition) “true stuff” else “false stuff”<br>

### This Week: 
Often, when you get a dataset, it is not in the format you want. You can (and should) use code to refine the dataset to become more useful. As Chapter 6 of Introduction to Data Science mentions, this is called “data munging.” In this homework, you will read in a dataset from the web and work on it (in a data frame) to improve its usefulness.


## Part 1: Use read_csv( ) to read a CSV file from the web into a data frame:

A.	Use R code to read directly from a URL on the web. Store the dataset into a new dataframe, called dfComps. <br>
The URL is:    <br>
"https://intro-datascience.s3.us-east-2.amazonaws.com/companies1.csv" <br>
**Hint:** use read_csv( ), not read.csv( ). This is from the **tidyverse package**. Check the help to compare them.



```{r}
#install.packages("tidyverse")
library(tidyverse)
dfComps <- data.frame(read_csv(url("https://intro-datascience.s3.us-east-2.amazonaws.com/companies1.csv")))


```

## Part 2: Create a new data frame that only contains companies with a homepage URL:

E.	Use **subsetting** to create a new dataframe that contains only the companies with homepage URLs (store that dataframe in **urlComps**).


```{r}
urlComps <- subset(dfComps, homepage_url != 'NA' )



```

D.	How many companies are missing a homepage URL?


```{r}
#3323
no_url <-dfComps[is.na(dfComps$homepage_url), ]                        
str(no_url)
 
```

## Part 3: Analyze the numeric variables in the dataframe.

G.	How many **numeric variables** does the dataframe have? You can figure that out by looking at the output of **str(urlComps)**. 

H.	What is the average number of funding rounds for the companies in **urlComps**?


```{r}
str(urlComps)
#G. 2 - funding rounds and founded year
mean(urlComps$funding_rounds)
#H.The average funding was 1.725194 rounds
```

I.	What year was the oldest company in the dataframe founded? <br>
**Hint:** If you get a value of “NA,” most likely there are missing values in this variable which preclude R from properly calculating the min & max values. You can ignore NAs with basic math calculations. For example, instead of running mean(urlComps$founded_year), something like this will work for determining the average (note that this question needs to use a different function than 'mean'. 


```{r}
#mean(urlComps$founded_year, na.rm=TRUE)

#your code goes here
min(urlComps$founded_year, na.rm=TRUE)

#The oldest company was founded in 1900

## Part 4:  Use string operations to clean the data.




```{r}

```
K.	The **permalink variable** in **urlComps** contains the name of each company but the names are currently preceded by the prefix “/organization/”. We can use str_replace() in tidyverse or gsub() to clean the values of this variable:

```{r}
urlComps$permalink <- str_replace(urlComps$permalink, '/organization/', "" )

```

L.	Can you identify another variable which should be numeric but is currently coded as character? Use the as.numeric() function to add a new variable to **urlComps** which contains the values from the char variable as numbers. Do you notice anything about the number of NA values in this new column compared to the original “char” one?  


```{r}
glimpse(urlComps) 
# funding_total_usd should be numeric but is coded as a character
urlComps$funding_new <- as.numeric(urlComps$funding_total_usd) #code to convert values to numeric 
which(is.na(urlComps$funding_total_usd)) #finds index of any NA values
#which(is.na(urlComps$funding_new)) # all values are showing as NA
```

M.	To ensure the char values are converted correctly, we first need to remove the spaces between the digits in the variable. Check if this works, and explain what it is doing:


```{r}
library(stringi)
urlComps$funding_new <- stri_replace_all_charclass(urlComps$funding_total_usd,"\\p{WHITE_SPACE}", "")

#The above code is removing any whitespace that is found in the variable 
```


    Error in stri_replace_all_charclass(urlComps$funding_total_usd, "\\p{WHITE_SPACE}", : object 'urlComps' not found
    Traceback:


    1. stri_replace_all_charclass(urlComps$funding_total_usd, "\\p{WHITE_SPACE}", 
     .     "")


N. You are now ready to convert **urlComps$funding_new** to numeric using as.numeric(). 

Calculate the average funding amount for **urlComps**. If you get “NA,” try using the **na.rm=TRUE** argument from problem I.


```{r}
urlComps$funding_new <- as.numeric(urlComps$funding_new)
mean(urlComps$funding_new, na.rm=TRUE)
# Mean for funding is 18321551
```

Sample three unique observations from urlComps$funding_rounds, store the results in the vector 'observations'


```{r}
obvervations <- sample(urlComps$funding_rounds, size = 3, replace = TRUE)
obvervations
```

Take the mean of those observations


```{r}
mean(obvervations)
```

Do the two steps (sampling and taking the mean) in one line of code


```{r}
 mean(sample(urlComps$funding_rounds, size = 3, replace = TRUE))
```

Explain why the two means are (or might be) different
```{r}
# The two means are different because each sample being taken has different values from the sample size. 
```

Use the replicate( ) function to repeat your sampling of three observations of urlComps$funding_rounds  observations five times. The first argument to replicate( ) is the number of repeats you want. The second argument is the little chunk of code you want repeated.


```{r}
funding_sample <- replicate(5,mean(sample(urlComps$funding_rounds, size = 3, replace = TRUE)), simplify = TRUE)
funding_sample

```

Rerun your replication, this time doing 20 replications and storing the output of replicate() in a variable called **values**.


```{r}
 values  <- replicate(20,mean(sample(urlComps$funding_rounds, size = 3, replace = TRUE)),simplify = TRUE)

```

Generate a **histogram** of the means stored in **values**. 


```{r}
hist(values)

```

Rerun your replication, this time doing 1000 replications and storing the output of replicate() in a variable called **values**, and then generate a histogram of **values**.


```{r}
values <- replicate(1000,mean(sample(urlComps$funding_rounds, size = 3, replace = TRUE)),simplify = TRUE)
hist(values)

```

Repeat the replicated sampling, but this time, raise your sample size from 3 to 22. How does that affect your histogram? Explain in a comment.


```{r}
values <- replicate(1000,mean(sample(urlComps$funding_rounds, size = 22, replace = TRUE)),simplify = TRUE)
hist(values) 

# When the sample size is 22, the distribution of the frequency is closer to a normal distribution. This is because you have a larger population size, which is more representative of the entire population 
```

Explain in a comment below, the last three histograms, why do they look different?


```{r}
# Each histogram looks different because the number of replications and sample size is different. The first and second graph have the same population size of 3 which is relatively small. The middle graph has a higher replication number, and shows that the distribution skews to the right. The last graph has a larger sample size and has a more normal distribution since it has a better representation of the population. The standard devation on this graph is also lower than the first two graphs. 
```
